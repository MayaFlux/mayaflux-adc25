<!doctype html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>MayaFlux: Digital-First Multimedia Processing</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/firacode@6.2.0/distr/fira_code.css" />
    <style>
        body {
            font-family: "Georgia", "Times New Roman", serif;
            background-color: #181a20;
            color: #e2e4ea;
            line-height: 1.6;
            max-width: 1100px;
            margin: 40px auto;
            padding: 0 20px;
        }

        h1,
        h2,
        h3 {
            font-family: "Fira Code", "JetBrains Mono", monospace;
            font-weight: 600;
            color: #e7e9f3;
            letter-spacing: 0.5px;
        }

        h1 {
            font-size: 2.2em;
            margin-bottom: 0.2em;
            text-align: center;
            color: #b7c4ff;
        }

        h2 {
            color: #b7c4ff;
            font-size: 1.15em;
        }

        .subtitle {
            font-style: italic;
            color: #a3a7c7;
            margin-bottom: 2em;
            text-align: center;
            font-family: "Georgia", serif;
        }

        .problem-statement {
            background: rgba(122, 122, 217, 0.08);
            border-left: 4px solid #7a7ad9;
            padding: 1.2em;
            margin-bottom: 2em;
            border-radius: 4px;
            font-size: 0.95em;
        }

        .twopane {
            display: flex;
            gap: 32px;
            margin-bottom: 2em;
        }

        .pane {
            flex: 1;
            min-width: 0;
            display: flex;
            flex-direction: column;
            gap: 1.5em;
        }

        .section-box {
            background: #23253a;
            border: 1px solid #2e3147;
            border-radius: 8px;
            padding: 1.1em 1em;
            margin-bottom: 0;
            box-shadow: 0 2px 8px rgba(60, 70, 120, 0.07);
        }

        .section-box h3 {
            margin-top: 0;
            margin-bottom: 0.6em;
            font-size: 1em;
        }

        .edge-box {
            background: #23253a;
            border-left: 4px solid #7a7ad9;
            padding: 1.2em 1em;
            margin: 2em 0;
            font-size: 0.95em;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(122, 122, 217, 0.07);
        }

        .edge-title {
            font-weight: bold;
            color: #b7c4ff;
            margin-bottom: 0.5em;
            display: block;
            font-family: "Fira Code", monospace;
        }

        .emphasis {
            color: #7a7ad9;
            font-weight: bold;
        }

        .tech-detail {
            color: #a3a7c7;
            font-size: 0.9em;
            margin-top: 0.4em;
        }

        ul {
            list-style-type: square;
            margin-left: 1.2em;
            margin-top: 0.5em;
        }

        ul li {
            color: #e2e4ea;
            margin-bottom: 0.4em;
        }

        .capability {
            margin-bottom: 1em;
        }

        .capability-title {
            font-weight: bold;
            color: #b7c4ff;
        }

        .status-box {
            background: #1a1d2a;
            border: 1px solid #2e3147;
            padding: 0.8em;
            margin-top: 1em;
            border-radius: 4px;
            font-size: 0.9em;
        }

        .status-item {
            margin-bottom: 0.5em;
        }

        .status-check {
            color: #7a7ad9;
            font-weight: bold;
        }

        footer {
            border-top: 1px solid #2e3147;
            margin-top: 2.5em;
            padding-top: 1em;
            font-size: 0.9em;
            color: #a3a7c7;
            text-align: center;
            font-family: "Georgia", serif;
        }

        @media (max-width: 900px) {
            .twopane {
                flex-direction: column;
                gap: 0;
            }

            .pane {
                gap: 1em;
            }
        }
    </style>
</head>

<body>
    <h1>MayaFlux</h1>
    <div class="subtitle">
        Unified Multimedia DSP: Moving Beyond Audio-Centric Thinking
    </div>

    <div class="problem-statement">
        <strong>The Problem:</strong> Every creative coding framework asks you to
        chooseâ€”real-time audio precision <em>or</em> flexible visual programming,
        never both with unified timing. Audio tools ignore graphics. Graphics
        frameworks sacrifice audio accuracy. MayaFlux eliminates this false
        choice.
    </div>

    <div class="twopane">
        <div class="pane">
            <div class="section-box">
                <h2>What Becomes Possible</h2>
                <p>
                    When audio, visual, and control data share a single computational
                    substrate:
                </p>
                <ul>
                    <li>
                        <span class="capability-title">Direct cross-modal flow:</span>
                        Audio features feed compute shaders and render pipelines without
                        translation layers.
                    </li>
                    <li>
                        <span class="capability-title">Live algorithmic authorship:</span>
                        Modify audio and visual algorithms while they process, sub-buffer
                        latency. +Live coding via LLVM21 JIT
                    </li>
                    <li>
                        <span class="capability-title">Recursive composition:</span> Treat
                        time as creative material via C++20 coroutines (impossible in
                        traditional DSP).
                    </li>
                    <li>
                        <span class="capability-title">Sample-accurate coordination:</span>
                        Audio ticks at sample rate, graphics at frame rate, both within
                        unified scheduling. 100% lock free synchronization.
                    </li>
                    <li>
                        <span class="capability-title">Adaptive pipelines:</span>
                        Algorithms self-configure based on data characteristics at
                        runtime.
                    </li>
                </ul>
            </div>

            <div class="section-box">
                <h3>Architecture: Not Feature Lists, But Principles</h3>
                <p>Five composable paradigms replace analog-inspired thinking:</p>
                <ul>
                    <li>
                        <span class="emphasis">Nodes</span>: Unit-by-unit transformation
                        precision, maintaining mathematical relationships as creative
                        decisions.
                    </li>
                    <li>
                        <span class="emphasis">Buffers</span>: Temporal gathering spaces
                        that accumulate data without blocking allocation.
                    </li>
                    <li>
                        <span class="emphasis">Coroutines</span: Time itself becomes malleable through C++20 suspension
                                and resumption primitives. </li>
                    <li>
                        <span class="emphasis">Containers</span>: Multi-dimensional data
                        unifying audio, visual, and tensor representations.
                    </li>
                    <li>
                        <span class="emphasis">Compute Matrix</span>: Composable and
                        expresssive semantic pipelines to analyze, sort, extract and
                        transform NDData .
                    </li>
                </ul>
                <p class="tech-detail">
                    All components remain composable and concurrent. Processing domains
                    are encoded via bit-field tokens, enabling type-safe cross-modal
                    coordination.
                </p>
            </div>
        </div>

        <div class="pane">
            <div class="section-box">
                <h3>Current Implementation Status</h3>

                <div class="status-box">
                    <div class="status-item">
                        <span class="status-check">âœ“ Production-Ready:</span> (Live Coding) C++20
                        JIT compilation (Lila, LLVM21), lock-free audio node graphs
                        (sample-accurate), comprehensive testing (700+ tests), 100,000+
                        lines of infrastructure, developed independently since March 2025.
                    </div>
                    <div class="status-item">
                        <span class="status-check">âœ“ Proof-of-Concept:</span> Vulkan
                        graphics pipeline (CPU â†’ GPU unified data flow), cross-domain
                        synchronization, NDData containers feeding GPU rendering.
                    </div>
                    <div class="status-item">
                        <span class="status-check">â†’ In Development:</span> GPU compute
                        shader integration, complex ND visual pipelines, full audio-visual
                        feedback loops, advanced scheduling.
                    </div>
                </div>

                <p class="tech-detail" style="margin-top: 1em">
                    The system already demonstrates the paradigm at audio scale.
                    Graphics POC validates that the architecture scales across domains.
                </p>
            </div>

            <div class="section-box">
                <h3>Why This Matters</h3>
                <p>
                    Existing tools inherited assumptions from analog hardware: separate
                    clocks, translation layers between domains, UI-first rather than
                    computation-first.
                </p>
                <p>
                    <span class="emphasis">MayaFlux asks: What if we started digital?</span>
                    Not simulating hardware, but embracing computational possibilities
                    that only exist in the digital realm: recursion, data-driven
                    pipelines, real-time code modification, unified cross-modal
                    processing.
                </p>
                <p class="tech-detail">
                    This isn't iteration on existing paradigms. It's a different
                    computational substrate.
                </p>
            </div>

            <div class="section-box">
                <h3>For Researchers & Developers</h3>
                <p>If you're interested in:</p>
                <ul style="margin-bottom: 0">
                    <li>
                        How to actually implement real-time DSP without sacrificing
                        flexibility
                    </li>
                    <li>Why coroutines enable new compositional paradigms</li>
                    <li>
                        What happens when you treat GPU and CPU as unified processing
                    </li>
                    <li>
                        Building production infrastructure for algorithmic composition
                    </li>
                </ul>
                <p style="margin-top: 0.8em; font-style: italic; color: #a3a7c7">
                    This is the foundational implementation. Everything is open source.
                </p>
            </div>
        </div>
    </div>

    <div class="edge-box">
        <span class="edge-title">The Paradigm Shift in One Sentence</span>
        Instead of asking "how do I optimize this for audio?" or "how do I make
        graphics precise?", MayaFlux asks: "What if audio, graphics, and
        algorithmic composition were just different modalities of the same
        computational material?"
    </div>

    <footer>
        Independent Developer Â· ADC25 Virtual Poster Â· 2025<br />
        <strong>GitHub:</strong> Open source, first alpha release: January 2026<br />
        <a href="mailto:mayafluxcollective@proton.me"><strong>Contact:</strong></a>
        Research collaborations + industry partnerships welcome<br />
        <a href="assets/technical.html">Technical Documentation</a>
        <a href="assets/tutorial.html">First MayaFlux Tutorial</a>
        <span style="font-size: 0.85em; color: #7c7f93">
            Licensed under GPL-3.0
        </span>
    </footer>
</body>
<style>
    .tech-doc-btn {
        position: fixed;
        bottom: 20px;
        right: 20px;
        background: #7a7ad9;
        color: white;
        padding: 12px 20px;
        border-radius: 6px;
        text-decoration: none;
        font-family: "Fira Code", monospace;
        font-size: 0.9em;
        box-shadow: 0 4px 12px rgba(122, 122, 217, 0.3);
        transition: all 0.3s;
        z-index: 1000;
    }

    .tech-doc-btn:hover {
        background: #b7c4ff;
        color: #1a1c24;
        transform: translateY(-2px);
    }

    .signup-btn {
        position: fixed;
        bottom: 20px;
        left: 20px;
        background: #4aa96c;
        color: white;
        padding: 12px 20px;
        border-radius: 6px;
        text-decoration: none;
        font-family: "Fira Code", monospace;
        font-size: 0.9em;
        box-shadow: 0 4px 12px rgba(74, 169, 108, 0.3);
        transition: all 0.3s;
        z-index: 1000;
    }

    .signup-btn:hover {
        background: #9be3b3;
        color: #1a1c24;
        transform: translateY(-2px);
    }
</style>

<a href="assets/technical.html" class="tech-doc-btn">ðŸ“„ Technical Docs</a>

<a href="https://github.com/MayaFlux/MayaFlux" class="signup-btn">ðŸ§© Source Repo! (pre-alpha)</a>

</html>
